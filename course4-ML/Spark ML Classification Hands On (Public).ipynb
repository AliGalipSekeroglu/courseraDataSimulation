{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data import using Spark ML\n",
    "from pyspark.sql import SQLContext\n",
    "#from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "#from pyspark.ml.feature import StringIndexer, VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095, 10)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pd.read_csv(\"daily_weather.csv\", sep=',', index_col=0)\n",
    "\n",
    "# How many samples ?\n",
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del f['relative_humidity_9am']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def functionG(row):\n",
    "    if row['relative_humidity_3pm'] < 25:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to Format (label, features)\n",
    "#g = f.copy(deep=True)\n",
    "#low_humidity = pd.DataFrame()\n",
    "\n",
    "f['label'] = f.apply(functionG, axis=1)\n",
    "\n",
    "#How many samples are in Class 1 (low humidity) ?\n",
    "f['label'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_pressure_9am</th>\n",
       "      <th>air_temp_9am</th>\n",
       "      <th>avg_wind_direction_9am</th>\n",
       "      <th>avg_wind_speed_9am</th>\n",
       "      <th>max_wind_direction_9am</th>\n",
       "      <th>max_wind_speed_9am</th>\n",
       "      <th>rain_accumulation_9am</th>\n",
       "      <th>rain_duration_9am</th>\n",
       "      <th>relative_humidity_3pm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1092.000000</td>\n",
       "      <td>1091.000000</td>\n",
       "      <td>1091.000000</td>\n",
       "      <td>1090.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>1093.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>1091.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>918.745860</td>\n",
       "      <td>64.658066</td>\n",
       "      <td>142.065256</td>\n",
       "      <td>5.647467</td>\n",
       "      <td>148.813945</td>\n",
       "      <td>7.212678</td>\n",
       "      <td>3.218741</td>\n",
       "      <td>469.232765</td>\n",
       "      <td>35.635732</td>\n",
       "      <td>0.500457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.204373</td>\n",
       "      <td>11.490511</td>\n",
       "      <td>69.247277</td>\n",
       "      <td>4.677773</td>\n",
       "      <td>67.921239</td>\n",
       "      <td>5.772890</td>\n",
       "      <td>37.516703</td>\n",
       "      <td>4613.974960</td>\n",
       "      <td>23.179102</td>\n",
       "      <td>0.500228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>907.990000</td>\n",
       "      <td>34.790000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.693451</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>1.185578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>916.450000</td>\n",
       "      <td>56.662304</td>\n",
       "      <td>64.900000</td>\n",
       "      <td>2.304048</td>\n",
       "      <td>75.897329</td>\n",
       "      <td>3.167080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.993620</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>918.890000</td>\n",
       "      <td>65.372000</td>\n",
       "      <td>165.296258</td>\n",
       "      <td>3.914645</td>\n",
       "      <td>177.050000</td>\n",
       "      <td>5.018724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.380000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>921.055433</td>\n",
       "      <td>73.292000</td>\n",
       "      <td>190.800000</td>\n",
       "      <td>7.714985</td>\n",
       "      <td>201.183418</td>\n",
       "      <td>9.416251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.790000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>927.610000</td>\n",
       "      <td>98.906000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>23.554978</td>\n",
       "      <td>314.700000</td>\n",
       "      <td>29.840780</td>\n",
       "      <td>655.334000</td>\n",
       "      <td>65487.000000</td>\n",
       "      <td>92.280000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       air_pressure_9am  air_temp_9am  avg_wind_direction_9am  \\\n",
       "count       1092.000000   1091.000000             1091.000000   \n",
       "mean         918.745860     64.658066              142.065256   \n",
       "std            3.204373     11.490511               69.247277   \n",
       "min          907.990000     34.790000               15.500000   \n",
       "25%          916.450000     56.662304               64.900000   \n",
       "50%          918.890000     65.372000              165.296258   \n",
       "75%          921.055433     73.292000              190.800000   \n",
       "max          927.610000     98.906000              333.000000   \n",
       "\n",
       "       avg_wind_speed_9am  max_wind_direction_9am  max_wind_speed_9am  \\\n",
       "count         1090.000000             1094.000000         1093.000000   \n",
       "mean             5.647467              148.813945            7.212678   \n",
       "std              4.677773               67.921239            5.772890   \n",
       "min              0.693451               28.900000            1.185578   \n",
       "25%              2.304048               75.897329            3.167080   \n",
       "50%              3.914645              177.050000            5.018724   \n",
       "75%              7.714985              201.183418            9.416251   \n",
       "max             23.554978              314.700000           29.840780   \n",
       "\n",
       "       rain_accumulation_9am  rain_duration_9am  relative_humidity_3pm  \\\n",
       "count            1089.000000        1091.000000            1095.000000   \n",
       "mean                3.218741         469.232765              35.635732   \n",
       "std                37.516703        4613.974960              23.179102   \n",
       "min                 0.000000           0.000000               5.300000   \n",
       "25%                 0.000000           0.000000              16.993620   \n",
       "50%                 0.000000           0.000000              24.380000   \n",
       "75%                 0.000000           0.000000              52.790000   \n",
       "max               655.334000       65487.000000              92.280000   \n",
       "\n",
       "             label  \n",
       "count  1095.000000  \n",
       "mean      0.500457  \n",
       "std       0.500228  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del f['relative_humidity_3pm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'air_pressure_9am', u'air_temp_9am', u'avg_wind_direction_9am',\n",
       "       u'avg_wind_speed_9am', u'max_wind_direction_9am', u'max_wind_speed_9am',\n",
       "       u'rain_accumulation_9am', u'rain_duration_9am', u'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.columns[0:]\n",
    "#temp = f.map(lambda line:LabeledPoint(line[0],[line[1:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from pyspark.mllib.linalg import DenseVector \n",
    "cols = ['air_pressure_9am','air_temp_9am','avg_wind_direction_9am','avg_wind_speed_9am','max_wind_direction_9am','max_wind_speed_9am','rain_accumulation_9am','rain_duration_9am']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from pyspark.mllib.linalg import Vectors, VectorUDT\n",
    "\n",
    "#w = pd.DataFrame()\n",
    "#w['fea'] = f[cols].apply(lambda x:','.join(x.map(str)), axis=1)\n",
    "\n",
    "#w['fea'] = [ f[c] for c in cols ]\n",
    "#w.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_pressure_9am</th>\n",
       "      <th>air_temp_9am</th>\n",
       "      <th>avg_wind_direction_9am</th>\n",
       "      <th>avg_wind_speed_9am</th>\n",
       "      <th>max_wind_direction_9am</th>\n",
       "      <th>max_wind_speed_9am</th>\n",
       "      <th>rain_accumulation_9am</th>\n",
       "      <th>rain_duration_9am</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921.551868</td>\n",
       "      <td>67.619839</td>\n",
       "      <td>197.965342</td>\n",
       "      <td>4.026048</td>\n",
       "      <td>210.834658</td>\n",
       "      <td>4.902075</td>\n",
       "      <td>1.020587e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>923.100000</td>\n",
       "      <td>75.596000</td>\n",
       "      <td>178.300000</td>\n",
       "      <td>1.409272</td>\n",
       "      <td>205.200000</td>\n",
       "      <td>1.856660</td>\n",
       "      <td>3.069545e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_pressure_9am  air_temp_9am  avg_wind_direction_9am  avg_wind_speed_9am  \\\n",
       "0        921.551868     67.619839              197.965342            4.026048   \n",
       "1        923.100000     75.596000              178.300000            1.409272   \n",
       "\n",
       "   max_wind_direction_9am  max_wind_speed_9am  rain_accumulation_9am  \\\n",
       "0              210.834658            4.902075           1.020587e-14   \n",
       "1              205.200000            1.856660           3.069545e-13   \n",
       "\n",
       "   rain_duration_9am  label  \n",
       "0                0.0      1  \n",
       "1                0.0      1  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.concat([low_humidity, f], axis = 1)\n",
    "#data.head(1)\n",
    "data = f.copy(deep=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(air_pressure_9am=921.5518680010001, air_temp_9am=67.6198391467, avg_wind_direction_9am=197.965342377, avg_wind_speed_9am=4.02604764663, max_wind_direction_9am=210.834657623, max_wind_speed_9am=4.9020753052399995, rain_accumulation_9am=1.0205866197799999e-14, rain_duration_9am=0.0, label=1),\n",
       " Row(air_pressure_9am=923.1, air_temp_9am=75.596, avg_wind_direction_9am=178.3, avg_wind_speed_9am=1.4092722, max_wind_direction_9am=205.2, max_wind_speed_9am=1.8566601999999999, rain_accumulation_9am=3.06954461848e-13, rain_duration_9am=0.0, label=1)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "dataDF = sqlContext.createDataFrame(data.dropna())\n",
    "dataDF.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_pressure_9am: double, air_temp_9am: double, avg_wind_direction_9am: double, avg_wind_speed_9am: double, max_wind_direction_9am: double, max_wind_speed_9am: double, rain_accumulation_9am: double, rain_duration_9am: double, label: bigint, features: vector]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "assembled = assembler.transform(dataDF)\n",
    "assembled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(assembled)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer= VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(assembled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = assembled.randomSplit([0.7, 0.3], seed = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",\n",
    "                  maxDepth=5, maxBins=32, minInstancesPerNode=20, minInfoGain=0.0,\n",
    "                  maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10,\n",
    "                  impurity=\"gini\")\n",
    "    \n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "# predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.832237 \n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"precision\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g \" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4b58bb9afac44f733c7f) of depth 5 with 39 nodes\n"
     ]
    }
   ],
   "source": [
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       1.0|         1.0|[910.21,43.501999...|\n",
      "|       0.0|         1.0|[910.34,50.72,174...|\n",
      "|       0.0|         0.0|[911.0,86.432,202...|\n",
      "|       0.0|         1.0|[912.9,78.332,167...|\n",
      "|       0.0|         1.0|[914.13,58.388000...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Accuracy = 0.519737 \n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from pyspark.ml.classification import NaiveBayes \n",
    "dtnb = NaiveBayes(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dtnb])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"precision\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g \" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data cleaning (removing missing values) - check summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Cleaning (replace with mean value) - check summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plots:\n",
    "\n",
    "# Histogram\n",
    "# Scatter Plot\n",
    "# Bar Plot\n",
    "# Box Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data preparation (adding new columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declaring Features and Target Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Data splitting into test and train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check Accuracy and Confusion Matrix of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the Naive Bayes Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check Accuracy and Confusion Matrix of Decision Tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
