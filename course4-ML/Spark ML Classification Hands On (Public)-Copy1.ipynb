{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download JAR from https://spark-packages.org/package/databricks/spark-csv (1.5.0)\n",
    "\n",
    "# Command to start: pyspark --packages com.databricks:spark-csv_2.11:1.5.0\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import DataFrameNaFunctions\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataDF = sqlContext.read.load('file:///home/cloudera/coursera/courseraDataSimulation/course4-ML/daily_weather.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true',inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['number',\n",
       " 'air_pressure_9am',\n",
       " 'air_temp_9am',\n",
       " 'avg_wind_direction_9am',\n",
       " 'avg_wind_speed_9am',\n",
       " 'max_wind_direction_9am',\n",
       " 'max_wind_speed_9am',\n",
       " 'rain_accumulation_9am',\n",
       " 'rain_duration_9am',\n",
       " 'relative_humidity_9am',\n",
       " 'relative_humidity_3pm']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+---------------------+\n",
      "|summary|            number|  air_pressure_9am|      air_temp_9am|avg_wind_direction_9am|avg_wind_speed_9am|max_wind_direction_9am|max_wind_speed_9am|rain_accumulation_9am|rain_duration_9am|relative_humidity_9am|relative_humidity_3pm|\n",
      "+-------+------------------+------------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+---------------------+\n",
      "|  count|              1095|              1092|              1090|                  1091|              1092|                  1092|              1091|                 1089|             1092|                 1095|                 1095|\n",
      "|   mean|             547.0| 918.8825513138097| 64.93300141287075|    142.23551070057584|  5.50828424225493|     148.9535179651692| 7.019513529175272|  0.20307895225211126|294.1080522756142|    34.24140205923539|    35.34472714825902|\n",
      "| stddev|316.24357700987383|3.1841611803868353|11.175514003175877|     69.13785928889183| 4.552813465531715|     67.23801294602951|  5.59820917078096|   1.5939521253574904|1598.078778660148|   25.472066802250044|    22.52407945358728|\n",
      "|    min|                 0| 907.9900000000024|36.752000000000685|    15.500000000000046|  0.69345139999974|     28.89999999999991|1.1855782000000479|                  0.0|              0.0|    6.090000000001012|   5.3000000000006855|\n",
      "|    max|              1094| 929.3200000000012| 98.90599999999992|                 343.4|23.554978199999763|    312.19999999999993| 29.84077959999996|    24.01999999999907|          17704.0|     92.6200000000002|     92.2500000000003|\n",
      "+-------+------------------+------------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air_pressure_9am',\n",
       " 'air_temp_9am',\n",
       " 'avg_wind_direction_9am',\n",
       " 'avg_wind_speed_9am',\n",
       " 'max_wind_direction_9am',\n",
       " 'max_wind_speed_9am',\n",
       " 'rain_accumulation_9am',\n",
       " 'rain_duration_9am',\n",
       " 'relative_humidity_9am',\n",
       " 'relative_humidity_3pm']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF = dataDF.drop('number') # row number\n",
    "dataDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: create a new column using Spark DataFrame (withColumn)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# Categorical Variable 'label'\n",
    "\n",
    "def functionG(row):\n",
    "    if row < 25:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "maximum recursion depth exceeded in cmp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e1761bf6c433>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfunct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mudf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mdata_time\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdate_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36mudf\u001b[1;34m(f, returnType)\u001b[0m\n\u001b[0;32m   1595\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \"\"\"\n\u001b[1;32m-> 1597\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mUserDefinedFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1599\u001b[0m \u001b[0mblacklist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'map'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'since'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore_unicode_prefix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, returnType, name)\u001b[0m\n\u001b[0;32m   1556\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturnType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1557\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_broadcast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1558\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_judf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_judf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1560\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create_judf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m_create_judf\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1567\u001b[0m         \u001b[0mpickled_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m         \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1569\u001b[1;33m         \u001b[0mjdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssql_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseDataType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1571\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__name__'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/context.py\u001b[0m in \u001b[0;36m_ssql_ctx\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    681\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_scala_HiveContext'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scala_HiveContext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_hive_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scala_HiveContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mPy4JError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/context.py\u001b[0m in \u001b[0;36m_get_hive_ctx\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_hive_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHiveContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefreshTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1186\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m             \"\\n\" + proto.END_COMMAND_PART)\n\u001b[0m\u001b[0;32m   1189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUCCESS_PACKAGE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mJavaPackage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjvm_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry)\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Exception while sending command.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 logging.exception(\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[1;32m/usr/lib/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry)\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Exception while sending command.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 logging.exception(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: maximum recursion depth exceeded in cmp"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "funct = udf(lambda data_time: date_time.day, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "maximum recursion depth exceeded in cmp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-2d474f93fe14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfunction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mudf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunctionG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdataDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36mudf\u001b[1;34m(f, returnType)\u001b[0m\n\u001b[0;32m   1595\u001b[0m     \u001b[1;33m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \"\"\"\n\u001b[1;32m-> 1597\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mUserDefinedFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1599\u001b[0m \u001b[0mblacklist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'map'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'since'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore_unicode_prefix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, returnType, name)\u001b[0m\n\u001b[0;32m   1556\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturnType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturnType\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1557\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_broadcast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1558\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_judf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_judf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1560\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create_judf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m_create_judf\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1567\u001b[0m         \u001b[0mpickled_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m         \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1569\u001b[1;33m         \u001b[0mjdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssql_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseDataType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturnType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1571\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__name__'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/context.py\u001b[0m in \u001b[0;36m_ssql_ctx\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    681\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_scala_HiveContext'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scala_HiveContext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_hive_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scala_HiveContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mPy4JError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/pyspark/sql/context.py\u001b[0m in \u001b[0;36m_get_hive_ctx\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_hive_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHiveContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefreshTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1186\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m             \"\\n\" + proto.END_COMMAND_PART)\n\u001b[0m\u001b[0;32m   1189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUCCESS_PACKAGE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mJavaPackage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjvm_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry)\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Exception while sending command.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 logging.exception(\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[1;32m/usr/lib/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry)\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Exception while sending command.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 logging.exception(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: maximum recursion depth exceeded in cmp"
     ]
    }
   ],
   "source": [
    "dataDF = dataDF.na.drop()\n",
    "\n",
    "W = dataDF.withColumn('label', functionG(\"relative_humidity_3pm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands On 1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(air_pressure_9am=918.0600000000087, air_temp_9am=74.82200000000041, avg_wind_direction_9am=271.1, avg_wind_speed_9am=2.080354199999768, max_wind_direction_9am=295.39999999999986, max_wind_speed_9am=2.863283199999908, rain_accumulation_9am=0.0, rain_duration_9am=0.0, relative_humidity_9am=42.42000000000046, relative_humidity_3pm=36.160000000000494),\n",
       " Row(air_pressure_9am=917.3476881177097, air_temp_9am=71.40384263106537, avg_wind_direction_9am=101.93517935618371, avg_wind_speed_9am=2.4430092157340217, max_wind_direction_9am=140.47154847112498, max_wind_speed_9am=3.5333236016106238, rain_accumulation_9am=0.0, rain_duration_9am=0.0, relative_humidity_9am=24.328697291802207, relative_humidity_3pm=19.4265967985621)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displat first few lines\n",
    "dataDF.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns in DataFrame\n",
    "len(dataDF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rows in DataFrame\n",
    "dataDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary| air_pressure_9am|\n",
      "+-------+-----------------+\n",
      "|  count|             1095|\n",
      "|   mean|              NaN|\n",
      "| stddev|              NaN|\n",
      "|    min|907.9900000000024|\n",
      "|    max|              NaN|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show summary of one column\n",
    "dataDF.describe(\"air_pressure_9am\").show()\n",
    "\n",
    "#Notice the Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+------------------+\n",
      "|summary| air_pressure_9am|      air_temp_9am|avg_wind_direction_9am|avg_wind_speed_9am|max_wind_direction_9am|max_wind_speed_9am|rain_accumulation_9am|rain_duration_9am|relative_humidity_3pm|             label|\n",
      "+-------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+------------------+\n",
      "|  count|             1092|              1092|                  1092|              1092|                  1092|              1092|                 1092|             1092|                 1092|              1092|\n",
      "|   mean|918.8825513138097|               NaN|                   NaN|               NaN|                   NaN|               NaN|                  NaN|              NaN|   35.275723107411714|0.5009157509157509|\n",
      "| stddev|3.184161180386832|               NaN|                   NaN|               NaN|                   NaN|               NaN|                  NaN|              NaN|   22.463394908910818|0.5002282561017957|\n",
      "|    min|907.9900000000024|36.752000000000685|    15.500000000000046|0.6934513999997399|     28.89999999999991| 1.185578200000048|                  0.0|              0.0|   5.3000000000006855|                 0|\n",
      "|    max|929.3200000000012|               NaN|                   NaN|               NaN|                   NaN|               NaN|                  NaN|              NaN|     92.2500000000003|                 1|\n",
      "+-------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the rows with missing values on specific column and show statistics\n",
    "dataDF = dataDF.na.drop(subset=['air_pressure_9am'])\n",
    "\n",
    "dataDF.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary| air_pressure_9am|\n",
      "+-------+-----------------+\n",
      "|  count|             1092|\n",
      "|   mean|918.8825513138097|\n",
      "| stddev|3.184161180386832|\n",
      "|    min|907.9900000000024|\n",
      "|    max|929.3200000000012|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the rows with missing values and check statistics\n",
    "dataDF.describe(\"air_pressure_9am\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation between two columns\n",
    "dataDF.stat.corr(\"rain_accumulation_9am\",\"rain_duration_9am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['air_pressure_9am','air_temp_9am','avg_wind_direction_9am','avg_wind_speed_9am','max_wind_direction_9am','max_wind_speed_9am','rain_accumulation_9am','rain_duration_9am']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands on 2: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values: Remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+------------------+\n",
      "|summary| air_pressure_9am|      air_temp_9am|avg_wind_direction_9am|avg_wind_speed_9am|max_wind_direction_9am|max_wind_speed_9am|rain_accumulation_9am|rain_duration_9am|relative_humidity_3pm|             label|\n",
      "+-------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+------------------+\n",
      "|  count|             1092|              1092|                  1092|              1092|                  1092|              1092|                 1092|             1092|                 1092|              1092|\n",
      "|   mean|918.8825513138097|               NaN|                   NaN|               NaN|                   NaN|               NaN|                  NaN|              NaN|   35.275723107411714|0.5009157509157509|\n",
      "| stddev|3.184161180386832|               NaN|                   NaN|               NaN|                   NaN|               NaN|                  NaN|              NaN|   22.463394908910818|0.5002282561017957|\n",
      "|    min|907.9900000000024|36.752000000000685|    15.500000000000046|0.6934513999997399|     28.89999999999991| 1.185578200000048|                  0.0|              0.0|   5.3000000000006855|                 0|\n",
      "|    max|929.3200000000012|               NaN|                   NaN|               NaN|                   NaN|               NaN|                  NaN|              NaN|     92.2500000000003|                 1|\n",
      "+-------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+-----------------+---------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove \n",
    "dataDF_remove = dataDF.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+------------------+\n",
      "|summary|  air_pressure_9am|      air_temp_9am|avg_wind_direction_9am|avg_wind_speed_9am|max_wind_direction_9am|max_wind_speed_9am|rain_accumulation_9am| rain_duration_9am|relative_humidity_3pm|             label|\n",
      "+-------+------------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+------------------+\n",
      "|  count|              1064|              1064|                  1064|              1064|                  1064|              1064|                 1064|              1064|                 1064|              1064|\n",
      "|   mean| 918.9031798641056| 65.02260949558739|    142.30675564934035| 5.485793050713691|    148.48042413321312|6.9997136588756925|  0.18202347650615522| 266.3936973996038|    35.14838093290537|0.5028195488721805|\n",
      "| stddev|3.1790395342048323|11.168033449415695|     69.14947215860059| 4.534427253459236|     67.15491055520597| 5.590789883333876|   1.5344932722397266|1503.0922161525934|    22.36547496676304|0.5002271745002914|\n",
      "|    min| 907.9900000000024|36.752000000000685|    15.500000000000046|0.6934513999997399|     28.89999999999991| 1.185578200000048|                  0.0|               0.0|   5.3000000000006855|                 0|\n",
      "|    max| 929.3200000000012| 98.90599999999992|                 343.4|23.554978199999766|    312.19999999999993|29.840779599999962|    24.01999999999907|           17704.0|     92.2500000000003|                 1|\n",
      "+-------+------------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF_remove.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+------------------+\n",
      "|summary| air_pressure_9am|      air_temp_9am|avg_wind_direction_9am|avg_wind_speed_9am|max_wind_direction_9am|max_wind_speed_9am|rain_accumulation_9am| rain_duration_9am|relative_humidity_3pm|             label|\n",
      "+-------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+------------------+\n",
      "|  count|             1092|              1092|                  1092|              1092|                  1092|              1092|                 1092|              1092|                 1092|              1092|\n",
      "|   mean|918.8825513138097| 64.67149057390388|    141.57780362528246| 5.489489334525926|    148.37845301711084| 6.988499373909827|  0.18912635439793885|286.86904128660325|   35.275723107411714|0.5009157509157509|\n",
      "| stddev|3.184161180386832|11.962373085058259|     69.43125901085068| 4.555746151594435|     67.43961519620014| 5.601519551446449|   1.5306721671167185|1581.7509523079502|   22.463394908910818|0.5002282561017957|\n",
      "|    min|907.9900000000024|               0.0|                   0.0|               0.0|                   0.0|               0.0|                  0.0|               0.0|   5.3000000000006855|                 0|\n",
      "|    max|929.3200000000012| 98.90599999999992|                 343.4|23.554978199999766|    312.19999999999993|29.840779599999962|    24.01999999999907|           17704.0|     92.2500000000003|                 1|\n",
      "+-------+-----------------+------------------+----------------------+------------------+----------------------+------------------+---------------------+------------------+---------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF_replace = dataDF.na.fill(0)\n",
    "dataDF_replace.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values : Replace with Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = f.fillna(f.mean())\n",
    "\n",
    "# TODO: spark\n",
    "\n",
    "# OR replace with Median\n",
    "#s = f.fillna(f.median()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_pressure_9am</th>\n",
       "      <th>air_temp_9am</th>\n",
       "      <th>avg_wind_direction_9am</th>\n",
       "      <th>avg_wind_speed_9am</th>\n",
       "      <th>max_wind_direction_9am</th>\n",
       "      <th>max_wind_speed_9am</th>\n",
       "      <th>rain_accumulation_9am</th>\n",
       "      <th>rain_duration_9am</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "      <td>1095.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>918.882551</td>\n",
       "      <td>64.933001</td>\n",
       "      <td>142.235511</td>\n",
       "      <td>5.508284</td>\n",
       "      <td>148.953518</td>\n",
       "      <td>7.019514</td>\n",
       "      <td>0.203079</td>\n",
       "      <td>294.108052</td>\n",
       "      <td>0.500457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.179792</td>\n",
       "      <td>11.149947</td>\n",
       "      <td>69.011349</td>\n",
       "      <td>4.546567</td>\n",
       "      <td>67.145759</td>\n",
       "      <td>5.587965</td>\n",
       "      <td>1.589575</td>\n",
       "      <td>1595.886124</td>\n",
       "      <td>0.500228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       air_pressure_9am  air_temp_9am  avg_wind_direction_9am  \\\n",
       "count       1095.000000   1095.000000             1095.000000   \n",
       "mean         918.882551     64.933001              142.235511   \n",
       "std            3.179792     11.149947               69.011349   \n",
       "\n",
       "       avg_wind_speed_9am  max_wind_direction_9am  max_wind_speed_9am  \\\n",
       "count         1095.000000             1095.000000         1095.000000   \n",
       "mean             5.508284              148.953518            7.019514   \n",
       "std              4.546567               67.145759            5.587965   \n",
       "\n",
       "       rain_accumulation_9am  rain_duration_9am        label  \n",
       "count            1095.000000        1095.000000  1095.000000  \n",
       "mean                0.203079         294.108052     0.500457  \n",
       "std                 1.589575        1595.886124     0.500228  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare the Summary Statistics\n",
    "s.describe().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands On 3: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete before classification\n",
    "dataDF = dataDF.drop('relative_humidity_9am')\n",
    "dataDF = dataDF.drop('relative_humidity_3pm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_pressure_9am: double, air_temp_9am: double, avg_wind_direction_9am: double, avg_wind_speed_9am: double, max_wind_direction_9am: double, max_wind_speed_9am: double, rain_accumulation_9am: double, rain_duration_9am: double, relative_humidity_3pm: double, label: bigint, features: vector]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "assembled = assembler.transform(dataDF)\n",
    "assembled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = assembled.randomSplit([0.7, 0.3], seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(assembled)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer= VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(assembled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       1.0|         1.0|[907.990000000002...|\n",
      "|       1.0|         1.0|[908.420000000007...|\n",
      "|       1.0|         1.0|[908.970000000004...|\n",
      "|       1.0|         1.0|[913.060000000003...|\n",
      "|       1.0|         0.0|[913.633267677041...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",\n",
    "                  maxDepth=5,  minInstancesPerNode=20, \n",
    "                  impurity=\"gini\")\n",
    "    \n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands On 4: Evaluation of Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.801917 \n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"precision\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g \" % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30, 124],\n",
       "       [127,  32]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(predictions.select('label').toPandas(), predictions.select('prediction').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
